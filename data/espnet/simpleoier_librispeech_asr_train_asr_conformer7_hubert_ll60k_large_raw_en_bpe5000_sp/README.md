<!-- Generated by scripts/utils/show_asr_result.sh -->
# LibriSpeech ESPNet2 Baseline
This folder stores the ESPNet2 simpleoier_librispeech_asr_train_asr_conformer7_hubert_ll60k_large_raw_en_bpe5000_sp system's 30-best 
recognition result for LibriSpeech dev_clean / dev_other / test_clean / test_other.

## Folder Structure

- raw_hypotheses
  - This is the ESPNet raw folder for 30-best output. Each nbest_recog/ folder contains the following files
    - score - the weighted sum score over decoder / ctc / lm scores. The score is computed as 
      - decoder * 0.6 + ctc * 0.4 + lm * 0.6
    - scores - the original decoder / ctc / lm score for each utterance
    - text - recognized text
    - token - recognized token sequence
    - token_int - recognized token sequence, in token index
- references
  - tokenized references for WER / CER / TER computation
- tokenized_hypotheses
  - tokenized recognition results for WER / CER / TER computation. The original hypothesis file is in raw_hypotheses/nbest_recog/text

The same line in the files from raw_hypotheses/, references/, and tokenized_hypotheses/ are corresponding to the same utterances.
Make sure you do not change the line order when operating those files.

## Performance Evaluation
The eval.sh is an example script for computing the WER/CER/TER.
Each dataset folder also contains precomputed result_wer.txt, result_cer.txt, and result_ter.txt. Those results
are computed base on hypothesis file in 1best_recog/ .

# LibriSpeech ESPNet2 Baseline RESULTS
## Environments
- date: `Wed Feb  9 04:24:56 UTC 2022`
- python version: `3.8.12 (default, Oct 12 2021, 13:49:34)  [GCC 7.5.0]`
- espnet version: `espnet 0.10.6a1`
- pytorch version: `pytorch 1.10.1`
- Git hash: `9284c63f0e5b4c903ea4d279eb069871c52d9a50`
  - Commit date: `Fri Feb 4 19:28:24 2022 -0500`

## simpleoier_librispeech_asr_train_asr_conformer7_hubert_ll60k_large_raw_en_bpe5000_sp
### WER

|dataset|Snt|Wrd|Corr|Sub|Del|Ins|Err|S.Err|
|---|---|---|---|---|---|---|---|---|
|decode_asr_lm_lm_train_lm_transformer2_en_bpe5000_valid.loss.ave_asr_model_valid.acc.ave/dev_clean|2703|54402|98.5|1.4|0.2|0.2|1.7|22.9|
|decode_asr_lm_lm_train_lm_transformer2_en_bpe5000_valid.loss.ave_asr_model_valid.acc.ave/dev_other|2864|50948|96.7|3.0|0.3|0.3|3.6|36.0|
|decode_asr_lm_lm_train_lm_transformer2_en_bpe5000_valid.loss.ave_asr_model_valid.acc.ave/test_clean|2620|52576|98.4|1.4|0.2|0.2|1.8|23.4|
|decode_asr_lm_lm_train_lm_transformer2_en_bpe5000_valid.loss.ave_asr_model_valid.acc.ave/test_other|2939|52343|96.6|3.1|0.3|0.4|3.7|37.2|

### CER

|dataset|Snt|Wrd|Corr|Sub|Del|Ins|Err|S.Err|
|---|---|---|---|---|---|---|---|---|
|decode_asr_lm_lm_train_lm_transformer2_en_bpe5000_valid.loss.ave_asr_model_valid.acc.ave/dev_clean|2703|288456|99.7|0.2|0.2|0.2|0.5|22.9|
|decode_asr_lm_lm_train_lm_transformer2_en_bpe5000_valid.loss.ave_asr_model_valid.acc.ave/dev_other|2864|265951|99.0|0.6|0.5|0.4|1.4|36.0|
|decode_asr_lm_lm_train_lm_transformer2_en_bpe5000_valid.loss.ave_asr_model_valid.acc.ave/test_clean|2620|281530|99.7|0.2|0.2|0.2|0.5|23.4|
|decode_asr_lm_lm_train_lm_transformer2_en_bpe5000_valid.loss.ave_asr_model_valid.acc.ave/test_other|2939|272758|99.1|0.5|0.4|0.4|1.3|37.2|

### TER

|dataset|Snt|Wrd|Corr|Sub|Del|Ins|Err|S.Err|
|---|---|---|---|---|---|---|---|---|
|decode_asr_lm_lm_train_lm_transformer2_en_bpe5000_valid.loss.ave_asr_model_valid.acc.ave/dev_clean|2703|68010|98.2|1.4|0.4|0.4|2.2|22.9|
|decode_asr_lm_lm_train_lm_transformer2_en_bpe5000_valid.loss.ave_asr_model_valid.acc.ave/dev_other|2864|63110|96.1|3.0|0.9|0.8|4.7|36.0|
|decode_asr_lm_lm_train_lm_transformer2_en_bpe5000_valid.loss.ave_asr_model_valid.acc.ave/test_clean|2620|65818|98.1|1.4|0.5|0.4|2.3|23.4|
|decode_asr_lm_lm_train_lm_transformer2_en_bpe5000_valid.loss.ave_asr_model_valid.acc.ave/test_other|2939|65101|96.1|2.9|1.1|0.7|4.6|37.2|

